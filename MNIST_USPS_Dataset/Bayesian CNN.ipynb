{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian tri-training for semi-supervised domain adaptation\n",
    "\n",
    "A tri-training bootstrapped approach to domain adaptation for MNIST to USPS using a Bayesian CNN.\n",
    "\n",
    "Author: @ysbecca, see my [personal blog](ybecca.github.io) for contact.\n",
    "\n",
    "Credits go to:\n",
    "\n",
    "- Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, for their work in \"Asymmetric Tri-training for Unsupervised Domain Adaptation\" which is used as a base for this approach.\n",
    "- [Hvass-Labs](http://www.hvass-labs.org/) for the base CNN model for MNIST classification. The basics of their CNN was customised and added to for this work.\n",
    "- [Leo Pauly](https://github.com/leopauly) for the research interest in general.\n",
    "- Kyle Dorman, Yarin Gal, Alex Kendall for their work in Bayesian deep learning (specific papers referenced below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from importlib import reload\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Custom scripts.\n",
    "import ysb\n",
    "import dataset\n",
    "import mnist_usps as mnus\n",
    "import cnn_helper as cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ysb' from '/Users/ysbecca/ysbecca-projects/Domain-Adaptation/MNIST_USPS_Dataset/ysb.py'>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mnus)\n",
    "reload(dataset)\n",
    "reload(cn)\n",
    "reload(ysb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shared net parameters\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 32         # There are 16 of these filters.\n",
    "\n",
    "filter_size2 = 5         \n",
    "num_filters2 = 48    \n",
    "\n",
    "\n",
    "\n",
    "# Individual net parameters (for now we assume both fully connected layers have the same number of units)\n",
    "fc_size = 100\n",
    "\n",
    "# IMAGE PARAMETERS\n",
    "img_size = 16             # Width and height in pixels.\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_data, usps_data = dataset.read_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset:\n",
      "- Training-set:\t\t49000\n",
      "- Test-set:\t\t14000\n",
      "- Validation-set:\t7000\n",
      "USPS dataset:\n",
      "- Training-set:\t\t7439\n",
      "- Test-set:\t\t1859\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST dataset:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(mnist_data.train.num_images))\n",
    "print(\"- Test-set:\\t\\t{}\".format(mnist_data.test.num_images))\n",
    "print(\"- Validation-set:\\t{}\".format(mnist_data.valid.num_images))\n",
    "\n",
    "print(\"USPS dataset:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(usps_data.train.num_images))\n",
    "print(\"- Test-set:\\t\\t{}\".format(usps_data.test.num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIAAAACNCAYAAADPeQGXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ade69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIAAAACNCAYAAADPeQGXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ade6978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "to_show = 10\n",
    "ysb.show_labeled_patches_gray(mnist_data.train.images[i:(i+to_show)], mnist_data.train.cls[i:(i+to_show)])\n",
    "ysb.show_labeled_patches_gray(usps_data.train.images[i:(i+to_show)], usps_data.train.cls[i:(i+to_show)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the four networks\n",
    "\n",
    "The first network, the shared network, will feed into the three tri-training networks: two labeling networks and one target-specific network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # So we can control dropout.\n",
    "keep_prob_target = tf.placeholder(tf.float32) # Separate dropout rate for the target-only network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build TensorFlow graph for the shared network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_net = \\\n",
    "    cn.new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)\n",
    "shared_net = \\\n",
    "    cn.new_conv_layer(input=shared_net,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)\n",
    "shared_net, features = cn.flatten_layer(shared_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the three independent networks, which are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Labeling network F1\n",
    "f1_net, _ = cn.new_fc_layer(input=shared_net,       \n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f1_net, f1_w_out = cn.new_fc_layer(input=f1_net,       \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob)\n",
    "f1_net, _ = cn.new_fc_layer(input=f1_net,             # This is the classification layer.\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,            # num_classes = 10\n",
    "                         use_relu=False)\n",
    "f1_y_pred = tf.nn.softmax(f1_net)                    \n",
    "f1_y_pred_cls = tf.argmax(f1_y_pred, dimension=1)\n",
    "\n",
    "\n",
    "# Labeling network F2\n",
    "f2_net, _ = cn.new_fc_layer(input=shared_net,\n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f2_net, f2_w_out = cn.new_fc_layer(input=f2_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob)\n",
    "f2_net, _ = cn.new_fc_layer(input=f2_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=True)\n",
    "f2_y_pred = tf.nn.softmax(f2_net)                    \n",
    "f2_y_pred_cls = tf.argmax(f2_y_pred, dimension=1)\n",
    "\n",
    "# # Labeling network F3\n",
    "f3_net, _ = cn.new_fc_layer(input=shared_net,\n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f3_net, _ = cn.new_fc_layer(input=f3_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob_target)\n",
    "f3_net, _ = cn.new_fc_layer(input=f3_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=True)\n",
    "f3_y_pred = tf.nn.softmax(f3_net)                    \n",
    "f3_y_pred_cls = tf.argmax(f3_y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the cost for each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost for the three networks\n",
    "f1_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f1_net, labels=y_true))\n",
    "f2_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f2_net, labels=y_true))\n",
    "f3_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f3_net, labels=y_true))\n",
    "\n",
    "# Overall tri-network costs, with a constraint for the weights of F1, F2 to force their inputs to be diffferent.\n",
    "weight_constraint = tf.reduce_sum( \\\n",
    "                        tf.abs( \\\n",
    "                        tf.multiply( \\\n",
    "                        tf.transpose(f1_w_out), f2_w_out)))\n",
    "cost = f1_cost + f2_cost + f3_cost + weight_constraint\n",
    "labeling_cost = f1_cost + f2_cost + weight_constraint\n",
    "target_only_cost = f3_cost\n",
    "\n",
    "# Optimisation functions\n",
    "initial_optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(f1_cost + f2_cost + f3_cost)\n",
    "optimizer_all = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "optimizer_f1f2 = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(labeling_cost)\n",
    "optimizer_f3 = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(target_only_cost)\n",
    "\n",
    "# Individual network accuracies\n",
    "f1_accuracy = tf.reduce_mean(tf.cast(tf.equal(f1_y_pred_cls, y_true_cls), tf.float32))\n",
    "f2_accuracy = tf.reduce_mean(tf.cast(tf.equal(f2_y_pred_cls, y_true_cls), tf.float32))\n",
    "f3_accuracy = tf.reduce_mean(tf.cast(tf.equal(f3_y_pred_cls, y_true_cls), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new TensorFlow session and initialise the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(0)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "train_batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for running optimisation iterations and showing test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(dataset_train, num_iterations, silent=False, dropout_keep_prob=1.0):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch = dataset_train.next_batch(train_batch_size)\n",
    "        x_batch = x_batch.reshape(len(x_batch), img_size_flat)\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch, keep_prob: dropout_keep_prob}\n",
    "\n",
    "        # [optimizer_all, optimizer_f1f2, optimizer_f3]\n",
    "        session.run(initial_optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 250 iterations.\n",
    "        if i % 250 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(f1_accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            if not silent:\n",
    "                msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "                print(msg.format(i + 1, acc))\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    if not silent:\n",
    "        print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "def print_test_accuracy(dataset_test, show_confusion_matrix=True, quieter=False, silent=False):\n",
    "    num_test = len(dataset_test.images)\n",
    "    cls_pred_f1 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    cls_pred_f2 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    cls_pred_f3 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        curr_batch_size = j - i\n",
    "        \n",
    "        # Get the images and targets from the test-set between index i and j.\n",
    "        images = dataset_test.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "        labels = dataset_test.labels[i:j, :]\n",
    "        feed_dict = {x: images, y_true: labels}\n",
    "\n",
    "        cls_pred_f1[i:j], cls_pred_f2[i:j], cls_pred_f3[i:j] = \\\n",
    "                        session.run([f1_y_pred_cls, f2_y_pred_cls, f3_y_pred_cls], feed_dict=feed_dict)\n",
    "        i = j\n",
    "\n",
    "    cls_true = dataset_test.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct_f1, correct_f2, correct_f3 = \\\n",
    "            (cls_true == cls_pred_f1), (cls_true == cls_pred_f2), (cls_true == cls_pred_f3)\n",
    "    \n",
    "    correct_sum_f1, correct_sum_f2, correct_sum_f3 = correct_f1.sum(), correct_f2.sum(), correct_f3.sum()\n",
    "    acc_f1, acc_f2, acc_f3 = \\\n",
    "        float(correct_sum_f1) / num_test, float(correct_sum_f2) / num_test, float(correct_sum_f3) / num_test\n",
    "\n",
    "    msg = \"Accuracy on test set: F1 {0:.1%}, F2 {1:.1%}, F3 {2:.1%}\"\n",
    "    if not quieter:\n",
    "        print(msg.format(acc_f1, acc_f2, acc_f3))\n",
    "    else:\n",
    "        if not silent:\n",
    "            print(msg.format(acc_f1, acc_f2, acc_f3))\n",
    "    \n",
    "    if show_confusion_matrix:\n",
    "        # Show confusion matrix for F3 only\n",
    "        cn.plot_confusion_matrix(cls_true, cls_pred=cls_pred_f2)\n",
    "    return acc_f1, acc_f2, acc_f3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we train all the networks on the labeled source data set.\n",
    "\n",
    "- MNIST to USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: F1 13.3%, F2 11.7%, F3 10.8%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13307142857142856, 0.11692857142857142, 0.1085)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  14.8%\n",
      "Time usage: 0:00:02\n"
     ]
    }
   ],
   "source": [
    "optimize(mnist_data.train, num_iterations=10, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: F1 18.7%, F2 15.2%, F3 25.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.18664285714285714, 0.15207142857142858, 0.24971428571428572)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize(mnist_data.train, num_iterations=15000, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: F1 98.4%, F2 98.4%, F3 98.4%\n",
      "[[1373    1    2    0    1    1    7    1    4    2]\n",
      " [   0 1552    2    1    0    0    2    5    1    1]\n",
      " [   3    1 1409    3    1    1    0    2    2    1]\n",
      " [   3    1   10 1406    0    9    1    5    9   11]\n",
      " [   0    0    1    0 1377    0    2    3    0    4]\n",
      " [   1    0    1    1    1 1233    5    1    2    5]\n",
      " [   5    2    0    0    4    0 1364    0    1    0]\n",
      " [   0    1   10    1    4    0    0 1424    1   11]\n",
      " [   0    2    6    4    8    4    6    0 1305    6]\n",
      " [   2    1    0    5   11    6    0    5    1 1329]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD3CAYAAAA+C7CYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1543b6668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.9836428571428572, 0.9837142857142858, 0.9843571428571428)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the CNN model which has been trained on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess=session, save_path='checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling function based on output of F1 and F2 and epistemic uncertainty (approximated) on target dataset\n",
    "\n",
    "\"We can model epistemic uncertainty in deep learning models using Monte Carlo dropout sampling at test time.\n",
    "Dropout sampling can be interpreted as sampling from a distribution over models.\"\n",
    "\n",
    "Credits:\n",
    "\n",
    "- Alex Kendall's presentation: https://alexgkendall.com/media/presentations/oxford_seminar.pdf\n",
    "- Yarin Gal's paper \"Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning\" http://proceedings.mlr.press/v48/gal16.pdf\n",
    "- Kyle Dorman's post \"Building a Bayesian Deep Learning Classifier\" https://medium.com/towards-data-science/building-a-bayesian-deep-learning-classifier-ece1845bc09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test on USPS test set, then run the CNN on the entire training set (we treat the training set as if it is completely unlabeled) and save softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_accuracy(usps_data.test, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# T is the number of iterations for sampling.\n",
    "def monte_carlo_preds(dataset_test, T, show_confusion_matrix=True, quieter=False, silent=False):\n",
    "    num_test = len(dataset_test.images)\n",
    "    all_cls_preds = np.zeros(shape=(T, num_test, 10), dtype=np.float64)\n",
    "    cls_true = dataset_test.cls\n",
    "    \n",
    "    if num_test == 0:\n",
    "        return [], []\n",
    "    \n",
    "    for k in range(T):\n",
    "        i = 0\n",
    "        cls_preds = np.zeros(shape=(num_test, 10), dtype=np.float64)\n",
    "        \n",
    "        while i < num_test:\n",
    "            j = min(i + test_batch_size, num_test)\n",
    "            curr_batch_size = j - i\n",
    "\n",
    "            # Get the images and targets from the test-set between index i and j.\n",
    "            images = dataset_test.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "            labels = dataset_test.labels[i:j, :]\n",
    "            feed_dict = {x: images, y_true: labels, keep_prob: 0.1}\n",
    "\n",
    "            # For each T iterations, we want all the softmax outputs from each prediction (N, 10)\n",
    "            # where N is the input size. all_cls_preds should have shape (T, N, 10).\n",
    "            cls_preds[i:j] = session.run(y_pred, feed_dict=feed_dict)\n",
    "            i = j\n",
    "\n",
    "        all_cls_preds[k] = cls_preds\n",
    "\n",
    "    # (N, 10)\n",
    "    prediction_probabilities = np.mean(all_cls_preds, axis=0)\n",
    "\n",
    "    # (N) one variance for each input.\n",
    "    prediction_variances = np.apply_along_axis(predictive_entropy, axis=1, arr=prediction_probabilities) \n",
    "\n",
    "    return prediction_probabilities, prediction_variances\n",
    "\n",
    "def predictive_entropy(prediction_probabilities):\n",
    "    return -1 * np.sum(np.log(prediction_probabilities) * prediction_probabilities, axis=0)\n",
    "\n",
    "def retrieve_predictions(dataset):\n",
    "    ''' Retrieves the probabilities (not predicted classes) on the given DataSet object. '''\n",
    "    num_test = len(dataset.images)\n",
    "\n",
    "    # Allocate an array for the class probabilities which will be calculated in batches and added\n",
    "    # onto this array; this first element is a dummy to maintain shape as we will add in batches.\n",
    "    cls_prob = np.zeros(shape=(1, num_classes), dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        curr_batch_size = j - i\n",
    "        images = dataset.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "        labels = dataset.labels[i:j, :]\n",
    "        feed_dict = {x: images, y_true: labels, keep_prob: 1.0}\n",
    "\n",
    "        # Save the softmax output.\n",
    "        cls_prob = np.concatenate((cls_prob, session.run(y_pred, feed_dict=feed_dict)), axis=0)\n",
    "        i = j\n",
    "    \n",
    "    cls_prob = np.delete(cls_prob, 0, 0) # Remove the first dummy element now.\n",
    "    return cls_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different thresholds, number of iterations, & threshold rates.\n",
    "\n",
    "Remember to reset the CNN model back to the checkpoint before each new experiment, as well as re-designating the dataset so that all MNIST images are training images, and the USPS set is divided into test (labelled) and train (unlabelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, uncertainties = monte_carlo_preds(usps_data.test, 50, show_confusion_matrix=True, quieter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will demonstrate that cases exist where bootstrapping using the softmax threshold would result in mislabelling, whereas the epistemic uncertainty provides a warning that the classifier is uncertain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "to_show = 20\n",
    "\n",
    "printed_uncertainty = [round(a, 4) for a in uncertainties]\n",
    "print(\"Labels: Epistemic uncertainty, softmax prediction, actual class.\")\n",
    "\n",
    "ysb.show_images_with_three_labels_gray(usps_data.test.images[i:(i+to_show)], printed_uncertainty[i:(i+to_show)], \\\n",
    "                                       np.argmax(preds[i:to_show], axis=1), usps_data.test.cls[i:to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to calculate, using the test round above, what the softmax threshold should be. We will look at the epistemic uncertainty for all the cases where the true class is different from the softmax prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, uncertainties, usps_data.test.cls\n",
    "\n",
    "case_epi_unc = []\n",
    "for i, pred in enumerate(np.argmax(preds, axis=1)):\n",
    "    if(pred != usps_data.test.cls[i]):\n",
    "        case_epi_unc.append(uncertainties[i])\n",
    "\n",
    "print(\"For the USPS test set:\")\n",
    "print(\"  - \" + str(len(case_epi_unc)) + \" cases.\")\n",
    "print(\"  - Mean uncertainty: \" + str(np.mean(case_epi_unc)))\n",
    "print(\"  - Maximum uncertainty: \" + str(np.max(case_epi_unc)))\n",
    "print(\"  - Minimum uncertainty: \" + str(np.min(case_epi_unc)))\n",
    "\n",
    "ysb.plot_with_legend(np.arange(len(case_epi_unc)), [np.sort(case_epi_unc)], [\"USPS test\"], \"Cases\", \"Uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: repeated iterations of labeling unlabeled images with LOW epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bootstrap_iterations = 75\n",
    "exp1_acc = []\n",
    "exp1_adds = []\n",
    "\n",
    "print(\"-- Experiment 1 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    # Run Monte Carlo sampling iterations to calculate epistemic uncertainty.\n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 50, show_confusion_matrix=False, quieter=True)\n",
    "    selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "    \n",
    "    exp1_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp1_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp1_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp1_acc)), [exp1_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp1_adds)), [exp1_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 2: repeated iterations of labeling unlabeled images with LOW epistemic uncertainty if the softmax output is HIGH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_acc = []\n",
    "exp2_adds = []\n",
    "\n",
    "print(\"-- Experiment 2 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    softmax_selected = cn.split_by_threshold(0.99, usps_train_preds, silent=True)\n",
    "    \n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 100, show_confusion_matrix=False, quieter=True)\n",
    "    bay_selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    selected = np.zeros((len(bay_selected)))\n",
    "    for j, s in enumerate(softmax_selected):\n",
    "        if s > 0 and bay_selected[j] > 0:\n",
    "            selected[j] = 1\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp2_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp2_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp2_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp2_acc)), [exp2_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp2_adds)), [exp2_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: repeated iterations of labeling unlabeled images with lower softmax output IF the epistemic uncertainty is low (ie, trust uncertainty more than the softmax output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3_acc = []\n",
    "exp3_adds = []\n",
    "\n",
    "print(\"-- Experiment 3 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    softmax_selected = cn.split_by_threshold(0.7, usps_train_preds, silent=True)\n",
    "    \n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 100, show_confusion_matrix=False, quieter=True)\n",
    "    bay_selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    selected = softmax_selected\n",
    "    for j, s in enumerate(softmax_selected):\n",
    "        if bay_selected[j] > 0:\n",
    "            selected[j] = 0 # Unselect the ones\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp3_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp3_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp3_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp3_acc)), [exp3_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp3_adds)), [exp3_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: softmax threshold only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4_acc = []\n",
    "exp4_adds = []\n",
    "\n",
    "print(\"-- Experiment 4 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    # print(\"Round \" + str(i) + \":\", end=\" \")\n",
    "\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    selected = cn.split_by_threshold(0.99, usps_train_preds, silent=True)\n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp4_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, usps_train_preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp4_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison from both experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_range = min(len(exp1_acc), len(exp2_acc), len(exp3_acc), len(exp4_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(x_range), [exp1_acc[:x_range], exp2_acc[:x_range], exp3_acc[:x_range], exp4_acc[:x_range]], [\"Exp 1\", \"Exp 2\", \"Exp 3\", \"Exp 4\"], \"Iterations\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(x_range), [exp1_adds[:x_range], exp2_adds[:x_range], exp3_acc[:x_range], exp4_acc[:x_range]], [\"Exp 1\", \"Exp 2\", \"Exp 3\", \"Exp 4\"], \"Iterations\", \"No. images added per iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Close TensorFlow session\n",
    "\n",
    "Releases all resources! Run only when prepared to lose saved CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
