{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian tri-training for semi-supervised domain adaptation\n",
    "\n",
    "A tri-training bootstrapped approach to domain adaptation for MNIST to USPS using a Bayesian CNN.\n",
    "\n",
    "Author: @ysbecca, see my [personal blog](ybecca.github.io) for contact.\n",
    "\n",
    "Credits go to:\n",
    "\n",
    "- Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, for their work in \"Asymmetric Tri-training for Unsupervised Domain Adaptation\" which is used as a base for this approach.\n",
    "- [Hvass-Labs](http://www.hvass-labs.org/) for the base CNN model for MNIST classification. Their CNN was deepened and adjusted to iteratively for this work.\n",
    "- [Leo Pauly](https://github.com/leopauly) for the research interest in general.\n",
    "- Kyle Dorman, Yarin Gal, Alex Kendall for their work in Bayesian deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from importlib import reload\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Custom scripts.\n",
    "import ysb\n",
    "import dataset\n",
    "import mnist_usps as mnus\n",
    "import cnn_helper as cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ysb' from '/Users/ysbecca/ysbecca-projects/Domain-Adaptation/MNIST_USPS_Dataset/ysb.py'>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mnus)\n",
    "reload(dataset)\n",
    "reload(cn)\n",
    "reload(ysb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shared net parameters\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 32         # There are 16 of these filters.\n",
    "\n",
    "filter_size2 = 5         \n",
    "num_filters2 = 48    \n",
    "\n",
    "\n",
    "\n",
    "# Individual net parameters (for now we assume both fully connected layers have the same number of units)\n",
    "fc_size = 100\n",
    "\n",
    "# IMAGE PARAMETERS\n",
    "img_size = 16             # Width and height in pixels.\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_data, usps_data = dataset.read_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset:\n",
      "- Training-set:\t\t49000\n",
      "- Test-set:\t\t14000\n",
      "- Validation-set:\t7000\n",
      "USPS dataset:\n",
      "- Training-set:\t\t7439\n",
      "- Test-set:\t\t1859\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST dataset:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(mnist_data.train.num_images))\n",
    "print(\"- Test-set:\\t\\t{}\".format(mnist_data.test.num_images))\n",
    "print(\"- Validation-set:\\t{}\".format(mnist_data.valid.num_images))\n",
    "\n",
    "print(\"USPS dataset:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(usps_data.train.num_images))\n",
    "print(\"- Test-set:\\t\\t{}\".format(usps_data.test.num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIAAAACNCAYAAADPeQGXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ade69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIAAAACNCAYAAADPeQGXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ade6978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "to_show = 10\n",
    "ysb.show_labeled_patches_gray(mnist_data.train.images[i:(i+to_show)], mnist_data.train.cls[i:(i+to_show)])\n",
    "ysb.show_labeled_patches_gray(usps_data.train.images[i:(i+to_show)], usps_data.train.cls[i:(i+to_show)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the four networks\n",
    "\n",
    "The first network, the shared network, will feed into the three tri-training networks: two labeling networks and one target-specific network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # So we can control dropout.\n",
    "keep_prob_target = tf.placeholder(tf.float32) # Separate dropout rate for the target-only network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build TensorFlow graph for the shared network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_net = \\\n",
    "    cn.new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)\n",
    "shared_net = \\\n",
    "    cn.new_conv_layer(input=shared_net,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)\n",
    "shared_net, features = cn.flatten_layer(shared_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the three independent networks, which are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Labeling network F1\n",
    "f1_net, _ = cn.new_fc_layer(input=shared_net,       \n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f1_net, f1_w_out = cn.new_fc_layer(input=f1_net,       \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob)\n",
    "f1_net, _ = cn.new_fc_layer(input=f1_net,             # This is the classification layer.\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,            # num_classes = 10\n",
    "                         use_relu=False)\n",
    "f1_y_pred = tf.nn.softmax(f1_net)                    \n",
    "f1_y_pred_cls = tf.argmax(f1_y_pred, dimension=1)\n",
    "\n",
    "\n",
    "# Labeling network F2\n",
    "f2_net, _ = cn.new_fc_layer(input=shared_net,\n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f2_net, f2_w_out = cn.new_fc_layer(input=f2_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob)\n",
    "f2_net, _ = cn.new_fc_layer(input=f2_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=True)\n",
    "f2_y_pred = tf.nn.softmax(f2_net)                    \n",
    "f2_y_pred_cls = tf.argmax(f2_y_pred, dimension=1)\n",
    "\n",
    "# # Labeling network F3\n",
    "f3_net, _ = cn.new_fc_layer(input=shared_net,\n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f3_net, _ = cn.new_fc_layer(input=f3_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob_target)\n",
    "f3_net, _ = cn.new_fc_layer(input=f3_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=True)\n",
    "f3_y_pred = tf.nn.softmax(f3_net)                    \n",
    "f3_y_pred_cls = tf.argmax(f3_y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the cost for each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost for the three networks\n",
    "f1_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f1_net, labels=y_true))\n",
    "f2_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f2_net, labels=y_true))\n",
    "f3_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f3_net, labels=y_true))\n",
    "\n",
    "# Overall tri-network costs, with a constraint for the weights of F1, F2 to force their inputs to be diffferent.\n",
    "weight_constraint = tf.reduce_sum( \\\n",
    "                        tf.abs( \\\n",
    "                        tf.multiply( \\\n",
    "                        tf.transpose(f1_w_out), f2_w_out)))\n",
    "cost = f1_cost + f2_cost + f3_cost + weight_constraint\n",
    "labeling_cost = f1_cost + f2_cost + weight_constraint\n",
    "target_only_cost = f3_cost\n",
    "\n",
    "# Optimisation functions\n",
    "optimizer_all = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "optimizer_f1f2 = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(labeling_cost)\n",
    "optimizer_f3 = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(target_only_cost)\n",
    "\n",
    "# Individual network accuracies\n",
    "f1_accuracy = tf.reduce_mean(tf.cast(tf.equal(f1_y_pred_cls, y_true_cls), tf.float32))\n",
    "f2_accuracy = tf.reduce_mean(tf.cast(tf.equal(f2_y_pred_cls, y_true_cls), tf.float32))\n",
    "f3_accuracy = tf.reduce_mean(tf.cast(tf.equal(f3_y_pred_cls, y_true_cls), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new TensorFlow session and initialise the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(0)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "train_batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for running optimisation iterations and showing test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(dataset_train, num_iterations, silent=False, dropout_keep_prob=1.0):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch = dataset_train.next_batch(train_batch_size)\n",
    "        x_batch = x_batch.reshape(len(x_batch), img_size_flat)\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch, keep_prob: dropout_keep_prob}\n",
    "\n",
    "        # [optimizer_all, optimizer_f1f2, optimizer_f3]\n",
    "        session.run(optimizer_all, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 250 iterations.\n",
    "        if i % 250 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(f1_accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            if not silent:\n",
    "                msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "                print(msg.format(i + 1, acc))\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    if not silent:\n",
    "        print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "def print_test_accuracy(dataset_test, show_confusion_matrix=True, quieter=False, silent=False):\n",
    "    num_test = len(dataset_test.images)\n",
    "    cls_pred_f1 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    cls_pred_f2 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    cls_pred_f3 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        curr_batch_size = j - i\n",
    "        \n",
    "        # Get the images and targets from the test-set between index i and j.\n",
    "        images = dataset_test.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "        labels = dataset_test.labels[i:j, :]\n",
    "        feed_dict = {x: images, y_true: labels}\n",
    "\n",
    "        cls_pred_f1[i:j], cls_pred_f2[i:j], cls_pred_f3[i:j] = \\\n",
    "                        session.run([f1_y_pred_cls, f2_y_pred_cls, f3_y_pred_cls], feed_dict=feed_dict)\n",
    "        i = j\n",
    "\n",
    "    cls_true = dataset_test.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct_f1, correct_f2, correct_f3 = \\\n",
    "            (cls_true == cls_pred_f1), (cls_true == cls_pred_f2), (cls_true == cls_pred_f3)\n",
    "    \n",
    "    correct_sum_f1, correct_sum_f2, correct_sum_f3 = correct_f1.sum(), correct_f2.sum(), correct_f3.sum()\n",
    "    acc_f1, acc_f2, acc_f3 = \\\n",
    "        float(correct_sum_f1) / num_test, float(correct_sum_f2) / num_test, float(correct_sum_f3) / num_test\n",
    "\n",
    "    msg = \"Accuracy on test set: F1 {0:.1%}, F2 {1:.1%}, F3 {2:.1%}\"\n",
    "    if not quieter:\n",
    "        print(msg.format(acc_f1, acc_f2, acc_f3))\n",
    "    else:\n",
    "        if not silent:\n",
    "            print(msg.format(acc_f1, acc_f2, acc_f3))\n",
    "    \n",
    "    if show_confusion_matrix:\n",
    "        # Show confusion matrix for F1 only\n",
    "        cn.plot_confusion_matrix(cls_true, cls_pred=cls_pred_f1)\n",
    "    return acc_f1, acc_f2, acc_f3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we train all the networks on the labeled source data set.\n",
    "\n",
    "- MNIST to USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 10.4% (1460 / 14000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10428571428571429"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   8.6%\n",
      "Time usage: 0:00:03\n"
     ]
    }
   ],
   "source": [
    "optimize(mnist_data.train, num_iterations=10, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize(mnist_data.train, num_iterations=20000, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: F1 98.5%, F2 89.2%, F3 89.8%\n",
      "[[1374    1    3    0    0    5    2    1    5    1]\n",
      " [   0 1549    3    0    0    0    2    4    6    0]\n",
      " [   2    1 1403    0    1    3    0    1   10    2]\n",
      " [   2    0    5 1403    0   14    0    2   22    7]\n",
      " [   1    0    0    0 1373    0    0    4    3    6]\n",
      " [   0    0    1    0    0 1242    0    1    4    2]\n",
      " [   3    2    1    0    4    8 1350    0    8    0]\n",
      " [   0    0    4    0    3    1    0 1434    6    4]\n",
      " [   1    0    2    2    1    6    0    0 1327    2]\n",
      " [   1    0    0    1    2    7    0    6    4 1339]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD3CAYAAAA+C7CYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVGLBJOIqEWCSUTU4v8BhbcTz6tp43kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x154c810f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.9852857142857143, 0.8923571428571428, 0.8981428571428571)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the CNN model which has been trained on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(sess=session, save_path='checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now compute prediction and epistemic uncertainty (approximated) on USPS dataset\n",
    "\n",
    "\"We can model epistemic uncertainty in deep learning models using Monte Carlo dropout sampling at test time.\n",
    "Dropout sampling can be interpreted as sampling from a distribution over models.\"\n",
    "\n",
    "Credits:\n",
    "\n",
    "- Alex Kendall's presentation: https://alexgkendall.com/media/presentations/oxford_seminar.pdf\n",
    "- Yarin Gal's paper \"Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning\" http://proceedings.mlr.press/v48/gal16.pdf\n",
    "- Kyle Dorman's post \"Building a Bayesian Deep Learning Classifier\" https://medium.com/towards-data-science/building-a-bayesian-deep-learning-classifier-ece1845bc09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test on USPS test set, then run the CNN on the entire training set (we treat the training set as if it is completely unlabeled) and save softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_accuracy(usps_data.test, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# T is the number of iterations for sampling.\n",
    "def monte_carlo_preds(dataset_test, T, show_confusion_matrix=True, quieter=False, silent=False):\n",
    "    num_test = len(dataset_test.images)\n",
    "    all_cls_preds = np.zeros(shape=(T, num_test, 10), dtype=np.float64)\n",
    "    cls_true = dataset_test.cls\n",
    "    \n",
    "    if num_test == 0:\n",
    "        return [], []\n",
    "    \n",
    "    for k in range(T):\n",
    "        i = 0\n",
    "        cls_preds = np.zeros(shape=(num_test, 10), dtype=np.float64)\n",
    "        \n",
    "        while i < num_test:\n",
    "            j = min(i + test_batch_size, num_test)\n",
    "            curr_batch_size = j - i\n",
    "\n",
    "            # Get the images and targets from the test-set between index i and j.\n",
    "            images = dataset_test.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "            labels = dataset_test.labels[i:j, :]\n",
    "            feed_dict = {x: images, y_true: labels, keep_prob: 0.1}\n",
    "\n",
    "            # For each T iterations, we want all the softmax outputs from each prediction (N, 10)\n",
    "            # where N is the input size. all_cls_preds should have shape (T, N, 10).\n",
    "            cls_preds[i:j] = session.run(y_pred, feed_dict=feed_dict)\n",
    "            i = j\n",
    "\n",
    "        all_cls_preds[k] = cls_preds\n",
    "\n",
    "    # (N, 10)\n",
    "    prediction_probabilities = np.mean(all_cls_preds, axis=0)\n",
    "\n",
    "    # (N) one variance for each input.\n",
    "    prediction_variances = np.apply_along_axis(predictive_entropy, axis=1, arr=prediction_probabilities) \n",
    "\n",
    "    return prediction_probabilities, prediction_variances\n",
    "\n",
    "def predictive_entropy(prediction_probabilities):\n",
    "    return -1 * np.sum(np.log(prediction_probabilities) * prediction_probabilities, axis=0)\n",
    "\n",
    "def retrieve_predictions(dataset):\n",
    "    ''' Retrieves the probabilities (not predicted classes) on the given DataSet object. '''\n",
    "    num_test = len(dataset.images)\n",
    "\n",
    "    # Allocate an array for the class probabilities which will be calculated in batches and added\n",
    "    # onto this array; this first element is a dummy to maintain shape as we will add in batches.\n",
    "    cls_prob = np.zeros(shape=(1, num_classes), dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        curr_batch_size = j - i\n",
    "        images = dataset.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "        labels = dataset.labels[i:j, :]\n",
    "        feed_dict = {x: images, y_true: labels, keep_prob: 1.0}\n",
    "\n",
    "        # Save the softmax output.\n",
    "        cls_prob = np.concatenate((cls_prob, session.run(y_pred, feed_dict=feed_dict)), axis=0)\n",
    "        i = j\n",
    "    \n",
    "    cls_prob = np.delete(cls_prob, 0, 0) # Remove the first dummy element now.\n",
    "    return cls_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different thresholds, number of iterations, & threshold rates.\n",
    "\n",
    "Remember to reset the CNN model back to the checkpoint before each new experiment, as well as re-designating the dataset so that all MNIST images are training images, and the USPS set is divided into test (labelled) and train (unlabelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, uncertainties = monte_carlo_preds(usps_data.test, 50, show_confusion_matrix=True, quieter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will demonstrate that cases exist where bootstrapping using the softmax threshold would result in mislabelling, whereas the epistemic uncertainty provides a warning that the classifier is uncertain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "to_show = 20\n",
    "\n",
    "printed_uncertainty = [round(a, 4) for a in uncertainties]\n",
    "print(\"Labels: Epistemic uncertainty, softmax prediction, actual class.\")\n",
    "\n",
    "ysb.show_images_with_three_labels_gray(usps_data.test.images[i:(i+to_show)], printed_uncertainty[i:(i+to_show)], \\\n",
    "                                       np.argmax(preds[i:to_show], axis=1), usps_data.test.cls[i:to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to calculate, using the test round above, what the softmax threshold should be. We will look at the epistemic uncertainty for all the cases where the true class is different from the softmax prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, uncertainties, usps_data.test.cls\n",
    "\n",
    "case_epi_unc = []\n",
    "for i, pred in enumerate(np.argmax(preds, axis=1)):\n",
    "    if(pred != usps_data.test.cls[i]):\n",
    "        case_epi_unc.append(uncertainties[i])\n",
    "\n",
    "print(\"For the USPS test set:\")\n",
    "print(\"  - \" + str(len(case_epi_unc)) + \" cases.\")\n",
    "print(\"  - Mean uncertainty: \" + str(np.mean(case_epi_unc)))\n",
    "print(\"  - Maximum uncertainty: \" + str(np.max(case_epi_unc)))\n",
    "print(\"  - Minimum uncertainty: \" + str(np.min(case_epi_unc)))\n",
    "\n",
    "ysb.plot_with_legend(np.arange(len(case_epi_unc)), [np.sort(case_epi_unc)], [\"USPS test\"], \"Cases\", \"Uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: repeated iterations of labeling unlabeled images with LOW epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bootstrap_iterations = 75\n",
    "exp1_acc = []\n",
    "exp1_adds = []\n",
    "\n",
    "print(\"-- Experiment 1 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    # Run Monte Carlo sampling iterations to calculate epistemic uncertainty.\n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 50, show_confusion_matrix=False, quieter=True)\n",
    "    selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "    \n",
    "    exp1_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp1_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp1_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp1_acc)), [exp1_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp1_adds)), [exp1_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 2: repeated iterations of labeling unlabeled images with LOW epistemic uncertainty if the softmax output is HIGH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_acc = []\n",
    "exp2_adds = []\n",
    "\n",
    "print(\"-- Experiment 2 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    softmax_selected = cn.split_by_threshold(0.99, usps_train_preds, silent=True)\n",
    "    \n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 100, show_confusion_matrix=False, quieter=True)\n",
    "    bay_selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    selected = np.zeros((len(bay_selected)))\n",
    "    for j, s in enumerate(softmax_selected):\n",
    "        if s > 0 and bay_selected[j] > 0:\n",
    "            selected[j] = 1\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp2_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp2_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp2_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp2_acc)), [exp2_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp2_adds)), [exp2_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: repeated iterations of labeling unlabeled images with lower softmax output IF the epistemic uncertainty is low (ie, trust uncertainty more than the softmax output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3_acc = []\n",
    "exp3_adds = []\n",
    "\n",
    "print(\"-- Experiment 3 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    softmax_selected = cn.split_by_threshold(0.7, usps_train_preds, silent=True)\n",
    "    \n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 100, show_confusion_matrix=False, quieter=True)\n",
    "    bay_selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    selected = softmax_selected\n",
    "    for j, s in enumerate(softmax_selected):\n",
    "        if bay_selected[j] > 0:\n",
    "            selected[j] = 0 # Unselect the ones\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp3_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp3_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp3_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp3_acc)), [exp3_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp3_adds)), [exp3_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: softmax threshold only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4_acc = []\n",
    "exp4_adds = []\n",
    "\n",
    "print(\"-- Experiment 4 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    # print(\"Round \" + str(i) + \":\", end=\" \")\n",
    "\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    selected = cn.split_by_threshold(0.99, usps_train_preds, silent=True)\n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp4_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, usps_train_preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp4_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison from both experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_range = min(len(exp1_acc), len(exp2_acc), len(exp3_acc), len(exp4_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(x_range), [exp1_acc[:x_range], exp2_acc[:x_range], exp3_acc[:x_range], exp4_acc[:x_range]], [\"Exp 1\", \"Exp 2\", \"Exp 3\", \"Exp 4\"], \"Iterations\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(x_range), [exp1_adds[:x_range], exp2_adds[:x_range], exp3_acc[:x_range], exp4_acc[:x_range]], [\"Exp 1\", \"Exp 2\", \"Exp 3\", \"Exp 4\"], \"Iterations\", \"No. images added per iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Close TensorFlow session\n",
    "\n",
    "Releases all resources! Run only when prepared to lose saved CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
