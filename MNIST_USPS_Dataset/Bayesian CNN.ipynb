{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian tri-training for semi-supervised domain adaptation\n",
    "\n",
    "A tri-training bootstrapped approach to domain adaptation for MNIST to USPS using a Bayesian CNN.\n",
    "\n",
    "Author: @ysbecca, see my [personal blog](ybecca.github.io) for contact.\n",
    "\n",
    "Credits go to:\n",
    "\n",
    "- Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, for their work in \"Asymmetric Tri-training for Unsupervised Domain Adaptation\" which is used as a base for this approach.\n",
    "- [Hvass-Labs](http://www.hvass-labs.org/) for the base CNN model for MNIST classification. The basics of their CNN was customised and added to for this work.\n",
    "- [Leo Pauly](https://github.com/leopauly) for the research interest in general.\n",
    "- Kyle Dorman, Yarin Gal, Alex Kendall for their work in Bayesian deep learning (specific papers referenced below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from importlib import reload\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Custom scripts.\n",
    "import ysb\n",
    "import dataset\n",
    "import mnist_usps as mnus\n",
    "import cnn_helper as cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ysb' from '/Users/ysbecca/ysbecca-projects/Domain-Adaptation/MNIST_USPS_Dataset/ysb.py'>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mnus)\n",
    "reload(dataset)\n",
    "reload(cn)\n",
    "reload(ysb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shared net parameters\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 32         # There are 16 of these filters.\n",
    "\n",
    "filter_size2 = 5         \n",
    "num_filters2 = 48    \n",
    "\n",
    "\n",
    "\n",
    "# Individual net parameters (for now we assume both fully connected layers have the same number of units)\n",
    "fc_size = 100\n",
    "\n",
    "# IMAGE PARAMETERS\n",
    "img_size = 16             # Width and height in pixels.\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_data, usps_data = dataset.read_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset:\n",
      "- Training-set:\t\t49000\n",
      "- Test-set:\t\t14000\n",
      "- Validation-set:\t7000\n",
      "USPS dataset:\n",
      "- Training-set:\t\t7439\n",
      "- Test-set:\t\t1859\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST dataset:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(mnist_data.train.num_images))\n",
    "print(\"- Test-set:\\t\\t{}\".format(mnist_data.test.num_images))\n",
    "print(\"- Validation-set:\\t{}\".format(mnist_data.valid.num_images))\n",
    "\n",
    "print(\"USPS dataset:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(usps_data.train.num_images))\n",
    "print(\"- Test-set:\\t\\t{}\".format(usps_data.test.num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIAAAACNCAYAAADPeQGXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ade69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIAAAACNCAYAAADPeQGXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ade6978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "to_show = 10\n",
    "ysb.show_labeled_patches_gray(mnist_data.train.images[i:(i+to_show)], mnist_data.train.cls[i:(i+to_show)])\n",
    "ysb.show_labeled_patches_gray(usps_data.train.images[i:(i+to_show)], usps_data.train.cls[i:(i+to_show)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the four networks\n",
    "\n",
    "The first network, the shared network, will feed into the three tri-training networks: two labeling networks and one target-specific network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # So we can control dropout.\n",
    "keep_prob_target = tf.placeholder(tf.float32) # Separate dropout rate for the target-only network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build TensorFlow graph for the shared network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_net = \\\n",
    "    cn.new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)\n",
    "shared_net = \\\n",
    "    cn.new_conv_layer(input=shared_net,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)\n",
    "shared_net, features = cn.flatten_layer(shared_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the three independent networks, which are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Labeling network F1\n",
    "f1_net, _ = cn.new_fc_layer(input=shared_net,       \n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f1_net, f1_w_out = cn.new_fc_layer(input=f1_net,       \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob)\n",
    "f1_net, _ = cn.new_fc_layer(input=f1_net,             # This is the classification layer.\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,            # num_classes = 10\n",
    "                         use_relu=False)\n",
    "f1_y_pred = tf.nn.softmax(f1_net)                    \n",
    "f1_y_pred_cls = tf.argmax(f1_y_pred, dimension=1)\n",
    "\n",
    "\n",
    "# Labeling network F2\n",
    "f2_net, _ = cn.new_fc_layer(input=shared_net,\n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f2_net, f2_w_out = cn.new_fc_layer(input=f2_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob)\n",
    "f2_net, _ = cn.new_fc_layer(input=f2_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=True)\n",
    "f2_y_pred = tf.nn.softmax(f2_net)                    \n",
    "f2_y_pred_cls = tf.argmax(f2_y_pred, dimension=1)\n",
    "\n",
    "# # Labeling network F3\n",
    "f3_net, _ = cn.new_fc_layer(input=shared_net,\n",
    "                         num_inputs=features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "f3_net, _ = cn.new_fc_layer(input=f3_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True, )\n",
    "#                          dropout_keep_rate=keep_prob_target)\n",
    "f3_net, _ = cn.new_fc_layer(input=f3_net,          \n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=True)\n",
    "f3_y_pred = tf.nn.softmax(f3_net)                    \n",
    "f3_y_pred_cls = tf.argmax(f3_y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the cost for each network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost for the three networks\n",
    "f1_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f1_net, labels=y_true))\n",
    "f2_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f2_net, labels=y_true))\n",
    "f3_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=f3_net, labels=y_true))\n",
    "\n",
    "# Overall tri-network costs, with a constraint for the weights of F1, F2 to force their inputs to be diffferent.\n",
    "weight_constraint = tf.reduce_sum( \\\n",
    "                        tf.abs( \\\n",
    "                        tf.multiply( \\\n",
    "                        tf.transpose(f1_w_out), f2_w_out)))\n",
    "cost = f1_cost + f2_cost + f3_cost + weight_constraint\n",
    "labeling_cost = f1_cost + f2_cost + weight_constraint\n",
    "target_only_cost = f3_cost\n",
    "\n",
    "# Optimisation functions\n",
    "optimizer_all = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "optimizer_f1f2 = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(labeling_cost)\n",
    "optimizer_f3 = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(target_only_cost)\n",
    "\n",
    "# Individual network accuracies\n",
    "f1_accuracy = tf.reduce_mean(tf.cast(tf.equal(f1_y_pred_cls, y_true_cls), tf.float32))\n",
    "f2_accuracy = tf.reduce_mean(tf.cast(tf.equal(f2_y_pred_cls, y_true_cls), tf.float32))\n",
    "f3_accuracy = tf.reduce_mean(tf.cast(tf.equal(f3_y_pred_cls, y_true_cls), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new TensorFlow session and initialise the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(0)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "train_batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for running optimisation iterations and showing test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "\n",
    "def optimize(dataset_train, num_iterations, silent=False, dropout_keep_prob=1.0):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "        x_batch, y_true_batch = dataset_train.next_batch(train_batch_size)\n",
    "        x_batch = x_batch.reshape(len(x_batch), img_size_flat)\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch, keep_prob: dropout_keep_prob}\n",
    "\n",
    "        # [optimizer_all, optimizer_f1f2, optimizer_f3]\n",
    "        session.run(optimizer_all, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 250 iterations.\n",
    "        if i % 250 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(f1_accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            if not silent:\n",
    "                msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "                print(msg.format(i + 1, acc))\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    if not silent:\n",
    "        print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "    \n",
    "def print_test_accuracy(dataset_test, show_confusion_matrix=True, quieter=False, silent=False):\n",
    "    num_test = len(dataset_test.images)\n",
    "    cls_pred_f1 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    cls_pred_f2 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    cls_pred_f3 = np.zeros(shape=num_test, dtype=np.int)\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        curr_batch_size = j - i\n",
    "        \n",
    "        # Get the images and targets from the test-set between index i and j.\n",
    "        images = dataset_test.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "        labels = dataset_test.labels[i:j, :]\n",
    "        feed_dict = {x: images, y_true: labels}\n",
    "\n",
    "        cls_pred_f1[i:j], cls_pred_f2[i:j], cls_pred_f3[i:j] = \\\n",
    "                        session.run([f1_y_pred_cls, f2_y_pred_cls, f3_y_pred_cls], feed_dict=feed_dict)\n",
    "        i = j\n",
    "\n",
    "    cls_true = dataset_test.cls\n",
    "\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct_f1, correct_f2, correct_f3 = \\\n",
    "            (cls_true == cls_pred_f1), (cls_true == cls_pred_f2), (cls_true == cls_pred_f3)\n",
    "    \n",
    "    correct_sum_f1, correct_sum_f2, correct_sum_f3 = correct_f1.sum(), correct_f2.sum(), correct_f3.sum()\n",
    "    acc_f1, acc_f2, acc_f3 = \\\n",
    "        float(correct_sum_f1) / num_test, float(correct_sum_f2) / num_test, float(correct_sum_f3) / num_test\n",
    "\n",
    "    msg = \"Accuracy on test set: F1 {0:.1%}, F2 {1:.1%}, F3 {2:.1%}\"\n",
    "    if not quieter:\n",
    "        print(msg.format(acc_f1, acc_f2, acc_f3))\n",
    "    else:\n",
    "        if not silent:\n",
    "            print(msg.format(acc_f1, acc_f2, acc_f3))\n",
    "    \n",
    "    if show_confusion_matrix:\n",
    "        # Show confusion matrix for F3 only\n",
    "        cn.plot_confusion_matrix(cls_true, cls_pred=cls_pred_f2)\n",
    "    return acc_f1, acc_f2, acc_f3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we train all the networks on the labeled source data set.\n",
    "\n",
    "- MNIST to USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: F1 9.6%, F2 10.9%, F3 11.8%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09614285714285714, 0.10864285714285714, 0.11842857142857142)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  11.7%\n",
      "Time usage: 0:00:02\n"
     ]
    }
   ],
   "source": [
    "optimize(mnist_data.train, num_iterations=10, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: F1 12.5%, F2 10.2%, F3 12.2%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.12514285714285714, 0.10164285714285715, 0.12171428571428572)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize(mnist_data.train, num_iterations=15000, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: F1 98.4%, F2 89.6%, F3 98.4%\n",
      "[[1382    0    1    0    0    0    3    0    5    1]\n",
      " [   0 1549    3    2    0    0    2    7    0    1]\n",
      " [   4    3 1405    5    1    0    0    2    2    1]\n",
      " [   6    0    7 1422    0    0    0    4    7    9]\n",
      " [   0    0    0    0 1378    0    0    5    1    3]\n",
      " [1169    2    3   26    1    0    8    4   16   21]\n",
      " [  16    2    0    0    3    0 1353    0    2    0]\n",
      " [   0    2    7    2    2    0    0 1431    2    6]\n",
      " [   4    3    8    8    5    0    1    0 1309    3]\n",
      " [   8    1    0    7   12    0    0    8    2 1322]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAD3CAYAAAA+C7CYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRC3+H7YGJ//yChUNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105fe0438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.984, 0.8965, 0.9835714285714285)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_test_accuracy(mnist_data.test, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the CNN model which has been trained on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess=session, save_path='checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling function based on output of F1 and F2 and epistemic uncertainty (approximated) on target dataset\n",
    "\n",
    "\"We can model epistemic uncertainty in deep learning models using Monte Carlo dropout sampling at test time.\n",
    "Dropout sampling can be interpreted as sampling from a distribution over models.\"\n",
    "\n",
    "Credits:\n",
    "\n",
    "- Alex Kendall's presentation: https://alexgkendall.com/media/presentations/oxford_seminar.pdf\n",
    "- Yarin Gal's paper \"Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning\" http://proceedings.mlr.press/v48/gal16.pdf\n",
    "- Kyle Dorman's post \"Building a Bayesian Deep Learning Classifier\" https://medium.com/towards-data-science/building-a-bayesian-deep-learning-classifier-ece1845bc09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test on USPS test set, then run the CNN on the entire training set (we treat the training set as if it is completely unlabeled) and save softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_test_accuracy(usps_data.test, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# T is the number of iterations for sampling.\n",
    "def monte_carlo_preds(dataset_test, T, show_confusion_matrix=True, quieter=False, silent=False):\n",
    "    num_test = len(dataset_test.images)\n",
    "    all_cls_preds = np.zeros(shape=(T, num_test, 10), dtype=np.float64)\n",
    "    cls_true = dataset_test.cls\n",
    "    \n",
    "    if num_test == 0:\n",
    "        return [], []\n",
    "    \n",
    "    for k in range(T):\n",
    "        i = 0\n",
    "        cls_preds = np.zeros(shape=(num_test, 10), dtype=np.float64)\n",
    "        \n",
    "        while i < num_test:\n",
    "            j = min(i + test_batch_size, num_test)\n",
    "            curr_batch_size = j - i\n",
    "\n",
    "            # Get the images and targets from the test-set between index i and j.\n",
    "            images = dataset_test.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "            labels = dataset_test.labels[i:j, :]\n",
    "            feed_dict = {x: images, y_true: labels, keep_prob: 0.1}\n",
    "\n",
    "            # For each T iterations, we want all the softmax outputs from each prediction (N, 10)\n",
    "            # where N is the input size. all_cls_preds should have shape (T, N, 10).\n",
    "            cls_preds[i:j] = session.run(y_pred, feed_dict=feed_dict)\n",
    "            i = j\n",
    "\n",
    "        all_cls_preds[k] = cls_preds\n",
    "\n",
    "    # (N, 10)\n",
    "    prediction_probabilities = np.mean(all_cls_preds, axis=0)\n",
    "\n",
    "    # (N) one variance for each input.\n",
    "    prediction_variances = np.apply_along_axis(predictive_entropy, axis=1, arr=prediction_probabilities) \n",
    "\n",
    "    return prediction_probabilities, prediction_variances\n",
    "\n",
    "def predictive_entropy(prediction_probabilities):\n",
    "    return -1 * np.sum(np.log(prediction_probabilities) * prediction_probabilities, axis=0)\n",
    "\n",
    "def retrieve_predictions(dataset):\n",
    "    ''' Retrieves the probabilities (not predicted classes) on the given DataSet object. '''\n",
    "    num_test = len(dataset.images)\n",
    "\n",
    "    # Allocate an array for the class probabilities which will be calculated in batches and added\n",
    "    # onto this array; this first element is a dummy to maintain shape as we will add in batches.\n",
    "    cls_prob = np.zeros(shape=(1, num_classes), dtype=np.int)\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "        curr_batch_size = j - i\n",
    "        images = dataset.images[i:j, :].reshape(curr_batch_size, img_size_flat)\n",
    "        labels = dataset.labels[i:j, :]\n",
    "        feed_dict = {x: images, y_true: labels, keep_prob: 1.0}\n",
    "\n",
    "        # Save the softmax output.\n",
    "        cls_prob = np.concatenate((cls_prob, session.run(y_pred, feed_dict=feed_dict)), axis=0)\n",
    "        i = j\n",
    "    \n",
    "    cls_prob = np.delete(cls_prob, 0, 0) # Remove the first dummy element now.\n",
    "    return cls_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different thresholds, number of iterations, & threshold rates.\n",
    "\n",
    "Remember to reset the CNN model back to the checkpoint before each new experiment, as well as re-designating the dataset so that all MNIST images are training images, and the USPS set is divided into test (labelled) and train (unlabelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, uncertainties = monte_carlo_preds(usps_data.test, 50, show_confusion_matrix=True, quieter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will demonstrate that cases exist where bootstrapping using the softmax threshold would result in mislabelling, whereas the epistemic uncertainty provides a warning that the classifier is uncertain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "to_show = 20\n",
    "\n",
    "printed_uncertainty = [round(a, 4) for a in uncertainties]\n",
    "print(\"Labels: Epistemic uncertainty, softmax prediction, actual class.\")\n",
    "\n",
    "ysb.show_images_with_three_labels_gray(usps_data.test.images[i:(i+to_show)], printed_uncertainty[i:(i+to_show)], \\\n",
    "                                       np.argmax(preds[i:to_show], axis=1), usps_data.test.cls[i:to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to calculate, using the test round above, what the softmax threshold should be. We will look at the epistemic uncertainty for all the cases where the true class is different from the softmax prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, uncertainties, usps_data.test.cls\n",
    "\n",
    "case_epi_unc = []\n",
    "for i, pred in enumerate(np.argmax(preds, axis=1)):\n",
    "    if(pred != usps_data.test.cls[i]):\n",
    "        case_epi_unc.append(uncertainties[i])\n",
    "\n",
    "print(\"For the USPS test set:\")\n",
    "print(\"  - \" + str(len(case_epi_unc)) + \" cases.\")\n",
    "print(\"  - Mean uncertainty: \" + str(np.mean(case_epi_unc)))\n",
    "print(\"  - Maximum uncertainty: \" + str(np.max(case_epi_unc)))\n",
    "print(\"  - Minimum uncertainty: \" + str(np.min(case_epi_unc)))\n",
    "\n",
    "ysb.plot_with_legend(np.arange(len(case_epi_unc)), [np.sort(case_epi_unc)], [\"USPS test\"], \"Cases\", \"Uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: repeated iterations of labeling unlabeled images with LOW epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bootstrap_iterations = 75\n",
    "exp1_acc = []\n",
    "exp1_adds = []\n",
    "\n",
    "print(\"-- Experiment 1 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    # Run Monte Carlo sampling iterations to calculate epistemic uncertainty.\n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 50, show_confusion_matrix=False, quieter=True)\n",
    "    selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "    \n",
    "    exp1_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp1_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp1_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp1_acc)), [exp1_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp1_adds)), [exp1_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment 2: repeated iterations of labeling unlabeled images with LOW epistemic uncertainty if the softmax output is HIGH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2_acc = []\n",
    "exp2_adds = []\n",
    "\n",
    "print(\"-- Experiment 2 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    softmax_selected = cn.split_by_threshold(0.99, usps_train_preds, silent=True)\n",
    "    \n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 100, show_confusion_matrix=False, quieter=True)\n",
    "    bay_selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    selected = np.zeros((len(bay_selected)))\n",
    "    for j, s in enumerate(softmax_selected):\n",
    "        if s > 0 and bay_selected[j] > 0:\n",
    "            selected[j] = 1\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp2_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp2_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp2_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp2_acc)), [exp2_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp2_adds)), [exp2_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: repeated iterations of labeling unlabeled images with lower softmax output IF the epistemic uncertainty is low (ie, trust uncertainty more than the softmax output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3_acc = []\n",
    "exp3_adds = []\n",
    "\n",
    "print(\"-- Experiment 3 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    softmax_selected = cn.split_by_threshold(0.7, usps_train_preds, silent=True)\n",
    "    \n",
    "    preds, uncertainties = monte_carlo_preds(data.usps_train, 100, show_confusion_matrix=False, quieter=True)\n",
    "    bay_selected = np.where(uncertainties < 0.3, 1, 0)\n",
    "    \n",
    "    selected = softmax_selected\n",
    "    for j, s in enumerate(softmax_selected):\n",
    "        if bay_selected[j] > 0:\n",
    "            selected[j] = 0 # Unselect the ones\n",
    "    \n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp3_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp3_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best percent accuracy: \" + str(np.max(exp3_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(len(exp3_acc)), [exp3_acc], [\"Accuracy\"], \"Iterations\", \"Accuracy\")\n",
    "ysb.plot_with_legend(np.arange(len(exp3_adds)), [exp3_adds], [\"No. images added\"], \"Iterations\", \"Images added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: softmax threshold only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess=session, save_path='checkpoints/')\n",
    "data = dataset.generate_combined_dataset(mnist_data, usps_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4_acc = []\n",
    "exp4_adds = []\n",
    "\n",
    "print(\"-- Experiment 4 --\")\n",
    "\n",
    "for i in range(bootstrap_iterations):\n",
    "    # print(\"Round \" + str(i) + \":\", end=\" \")\n",
    "\n",
    "    usps_train_preds = retrieve_predictions(data.usps_train)\n",
    "    selected = cn.split_by_threshold(0.99, usps_train_preds, silent=True)\n",
    "    if np.count_nonzero(selected) >= data.train.num_images or np.count_nonzero(selected) == 0:\n",
    "        print(\"Ending iterations early.\")\n",
    "        break\n",
    "        \n",
    "    exp4_adds.append(np.count_nonzero(selected))\n",
    "    data.train.add_to_set(selected, data.usps_train, usps_train_preds)\n",
    "    data.usps_train.remove_from_set(selected)\n",
    "    \n",
    "    optimize(data.train, num_iterations=1000, silent=True)\n",
    "    exp4_acc.append(print_test_accuracy(data.test, show_confusion_matrix=False, quieter=True, silent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison from both experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_range = min(len(exp1_acc), len(exp2_acc), len(exp3_acc), len(exp4_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(x_range), [exp1_acc[:x_range], exp2_acc[:x_range], exp3_acc[:x_range], exp4_acc[:x_range]], [\"Exp 1\", \"Exp 2\", \"Exp 3\", \"Exp 4\"], \"Iterations\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ysb.plot_with_legend(np.arange(x_range), [exp1_adds[:x_range], exp2_adds[:x_range], exp3_acc[:x_range], exp4_acc[:x_range]], [\"Exp 1\", \"Exp 2\", \"Exp 3\", \"Exp 4\"], \"Iterations\", \"No. images added per iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Close TensorFlow session\n",
    "\n",
    "Releases all resources! Run only when prepared to lose saved CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
